# ðŸ§ª Pulso-AI Pytest Configuration
# ConfiguraciÃ³n para testing con pytest

[tool.pytest.ini_options]
# Test discovery
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py", "tests.py"]
python_classes = ["Test*", "*Tests"]
python_functions = ["test_*"]

# Minimum pytest version
minversion = "7.0" # For pytest itself

# Add options
addopts = [
    # Output formatting
    "--verbose",
    "--tb=short", # Shorter traceback format
    "--strict-markers", # Fail if unknown markers are used
    "--strict-config",  # Fail if pytest config options are misspelled

    # Coverage (pytest-cov options)
    "--cov=src", # Directory to measure coverage for
    "--cov-report=term-missing:skip-covered", # Terminal report, skip fully covered files
    "--cov-report=html:htmlcov",              # HTML report in htmlcov/
    "--cov-report=xml:coverage.xml",          # XML report for CI
    "--cov-fail-under=80",                    # Fail if coverage is below 80%

    # Performance
    "--durations=10", # Show the 10 slowest tests

    # Parallel execution (uncomment for potentially faster tests on multi-core systems)
    # "-n auto",
]

# Test markers for organization
markers = [
    "unit: Unit tests (fast, isolated, no external dependencies)",
    "integration: Integration tests (slower, may use external services/dependencies)",
    "e2e: End-to-end tests (slowest, full system)",
    "slow: Tests that take more than a few seconds",
    "database: Tests that require database connection",
    "redis: Tests that require Redis connection",
    "bigquery: Tests that require BigQuery connection",
    "external: Tests that require external APIs",
    "client_specific: Tests specific to a client implementation (general)",
    "client_movistar: Tests specific to Movistar client",
    "client_claro: Tests specific to Claro client",
    "client_tigo: Tests specific to Tigo client",
    "cross_filtering: Tests for cross-filtering functionality",
    "auth: Authentication and authorization tests",
    "performance: Performance benchmark tests",
    "security: Security-related tests",
]

# Async support
asyncio_mode = "auto" # Automatically handle asyncio tests

# Filter warnings
# Process warnings according to the following list, first match wins.
# "error" will turn all warnings not explicitly ignored into errors.
filterwarnings = [
    "error", # Treat all warnings that are not ignored below as errors
    "ignore::UserWarning",
    "ignore::DeprecationWarning",
    "ignore::PendingDeprecationWarning",
    "ignore:.*unclosed.*:ResourceWarning", # Ignore common "unclosed file" resource warnings in tests
    "ignore:.*datetime.*:DeprecationWarning:botocore.*", # Specific ignore for botocore
]

# Test timeout (in seconds) for individual tests
timeout = 300

# Files and directories to ignore during collection
# Note: Ignoring conftest.py is unusual unless it's a top-level one not for tests.
# Fixtures in conftest.py within test directories are usually essential.
collect_ignore = [
    "setup.py",
    # "conftest.py", # Kept from feature branch; review if this is intended for all conftest.py files
]
# If you want to ignore conftest.py only in specific directories, consider collect_ignore_glob
# e.g., collect_ignore_glob = ["*/some_other_module/conftest.py"]


# Logging configuration
log_cli = true
log_cli_level = "INFO"
log_cli_format = "%(asctime)s [%(levelname)8s] %(name)s: %(message)s (%(filename)s:%(lineno)s)"
log_cli_date_format = "%Y-%m-%d %H:%M:%S"
log_auto_indent = true # Indent multiline log messages

# JUnit XML output for CI/CD
junit_family = "xunit2"
junit_logging = "system-out" # Log system-out and system-err to JUnit XML

# Coverage.py specific configuration (used by pytest-cov)
# This section provides finer-grained control over coverage.py
[tool.coverage.run]
source = ["src"] # Source files to measure
branch = true    # Measure branch coverage
parallel = true  # If running tests in parallel with pytest-xdist, set this
# concurrency = ["multiprocessing", "thread"] # Depending on your parallel setup

omit = [ # Files to exclude from coverage measurement
    "*/tests/*",
    "*/test_*",
    "*/__init__.py", # Often __init__.py files have no significant code
    "*/migrations/*",
    "*/venv/*",
    "*/env/*",
    ".*", # Hidden files/directories
    "setup.py",
    "conftest.py", # If they truly contain no coverable code
    "src/manage.py", # Example: Django manage.py
    "src/asgi.py",   # Example: ASGI entry point
    "src/wsgi.py",   # Example: WSGI entry point
]

[tool.coverage.report]
# Coverage reporting options
exclude_lines = [ # Lines to exclude from coverage statistics
    "pragma: no cover",
    "def __repr__",
    "def __str__",
    "if self.debug:",
    "if settings.DEBUG",
    "raise AssertionError",
    "raise NotImplementedError",
    "if 0:", # Typically used for dead code blocks
    "if __name__ == .__main__.:",
    "class .*\\bProtocol\\):", # For Protocol definitions in type hinting
    "@(abc\\.)?abstractmethod",
    "@(typing\\.)?overload",
    "else:", # Can be part of simple if/else that doesn't need separate branch test
    "pass", # Simple pass statements
    "\\.\\.\\.", # Ellipsis, often in stubs or abstract methods
]

ignore_errors = true # Don't stop if a file can't be parsed
show_missing = true  # Show line numbers of missing statements
skip_covered = false # In reports (not terminal), show all files, even 100% covered
precision = 2      # Precision for coverage percentages

[tool.coverage.html]
directory = "htmlcov"
show_contexts = true # Show test contexts for covered lines
title = "Pulso-AI Coverage Report"

[tool.coverage.xml]
output = "coverage.xml"
package_depth = 2 # Helps structure the XML report by package